{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What makes an NBA All-Star?\n",
    "### STAT 206 Final Project\n",
    "\n",
    "#### Matthew Barclay\n",
    "#### Riley Baumgarten\n",
    "#### Arvind Kamboh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg\n",
    "Pkg.activate(pwd())\n",
    "Pkg.instantiate()\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames\n",
    "using Plots, StatsPlots\n",
    "using Distributions\n",
    "using MLJ, MLJClusteringInterface\n",
    "using NearestNeighbors, StableRNGs, Random\n",
    "#import PlotlyJS as PJS#import because PlotlyJS overwrites all plots and statsplots\n",
    "#using Colors\n",
    "using MLJLIBSVMInterface\n",
    "using FreqTables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: \n",
    "\n",
    "In the landscape of professional basketball, achieving the status of an NBA All-Star represents a significant milestone in a basketball playerâ€™s career, symbolizing not only individual excellence but also recognition among peers and fans. Nevertheless, the process through which NBA players attain this distinction remains a multifaceted and often debated topic. This analysis project aims to investigate the determinants that influence the selection of NBA players as All-Stars. By examining factors such as point per game, minutes played, rebounds, and shot percentage, this project seeks to explore the dynamics shaping the All-Star selection process. \n",
    "\n",
    "## Data Summary: \n",
    "\n",
    "For this project, we used the NBA Player Stats Dataset for the 2022-2023 season, obtained from Kaggle. The actual data comes from the NBA statistical source Basketball Reference. This dataset comprises 500 rows and 30 columns, with each row representing an NBA player and each column denoting various statistical attributes such as points per game, assists, rebounds, and shooting percentages, among others. This dataset was augmented with outside data to include an additional column indicating whether a player has been selected as an All-Star in previous seasons, which provides valuable historical context for our analysis to distinguish the current players who were All-Stars. This dataset contains no missing values and presents a solid foundation for addressing our research question regarding the determinants influencing an NBA player's selection as an All-Star, given its comprehensive coverage of accurate player statistics and the NBA being such a highly data-driven organization.\n",
    "Source: https://www.kaggle.com/datasets/bryanchungweather/nba-players-data-2022-2023  \n",
    "\n",
    "Columns Description:\n",
    "1. Rk: Rank\n",
    "2. Player: Player's name\n",
    "3. Pos: Position\n",
    "4. Age: Player's age\n",
    "5. Tm: Team\n",
    "6. G: Games played\n",
    "7. GSpct: Games started percentage\n",
    "8. MP: Minutes played per game\n",
    "9. FG: Field goals per game\n",
    "10. FGA: Field goal attempts per game\n",
    "11. FGpct: Field goal percentage\n",
    "12. ThreeP: 3-point field goals per game\n",
    "13. ThreePA: 3-point field goal attempts per game\n",
    "14. ThreePpct: 3-point field goal percentage\n",
    "15. TwoP: 2-point field goals per game\n",
    "16. TwoPA: 2-point field goal attempts per game\n",
    "17. TwoPpct: 2-point field goal percentage\n",
    "18. eFGpct: Effective field goal percentage\n",
    "19. FT: Free throws per game\n",
    "20. FTA: Free throw attempts per game\n",
    "21. FTpct: Free throw percentage\n",
    "22. ORB: Offensive rebounds per game\n",
    "23. DRB: Defensive rebounds per game\n",
    "24. TRB: Total rebounds per game\n",
    "25. AST: Assists per game\n",
    "26. STL: Steals per game\n",
    "27. BLK: Blocks per game\n",
    "28. TOV: Turnovers per game\n",
    "29. PF: Personal fouls per game (committed)\n",
    "30. PPG: Points per game\n",
    "31. ALLSTAR: All-Star status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nbadf = CSV.read(\"nba_2022_2023.csv\", DataFrame, stringtype = String) |> dropmissing\n",
    "#describe(nbadf)\n",
    "rename!(nbadf,\n",
    "Symbol(\"FG%\")=>:FGpct,\n",
    "Symbol(\"3P\")=>:ThreeP,\n",
    "Symbol(\"3PA\")=>:ThreePA,\n",
    "Symbol(\"3P%\")=>:ThreePpct,\n",
    "Symbol(\"2P\")=>:TwoP,\n",
    "Symbol(\"2PA\")=>:TwoPA,\n",
    "Symbol(\"2P%\")=>:TwoPpct,\n",
    "Symbol(\"eFG%\")=>:eFGpct,\n",
    "Symbol(\"FT%\")=>:FTpct,\n",
    ":PTS=>:PPG\n",
    ")\n",
    "multiteam = filter(:Tm=>==(\"TOT\"),nbadf).Player #identify players on multiple teams\n",
    "filter!(row -> row.Tm==(\"TOT\") || !in(row.Player, multiteam),nbadf) #remove all rows but total for players on multiple teams\n",
    "#Convert multi-positional to their main position\n",
    "nbadf.Pos = first.(nbadf.Pos,2)\n",
    "#filter(:Pos => in([\"SG-PG\",\"SF-SG\",\"PG-SG\",\"SF-PF\",\"PF-C\",\"PF-SF\"]), nbadf)\n",
    "\n",
    "allstars = CSV.read(\"nba_2022_2023_allstars.csv\", DataFrame, stringtype = String)\n",
    "leftjoin!(nbadf,allstars, on = :Player => :NAME)\n",
    "replace!(nbadf.ALLSTAR, missing => \"N\")\n",
    "#filter(:ALLSTAR=>==(\"Y\"),nbadf)\n",
    "nbadf.GSpct = nbadf.GS ./ nbadf.G\n",
    "describe(nbadf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question: \n",
    "\n",
    "> What are the determinant factors influencing an NBA player's selection as an All-Star?\n",
    "\n",
    "## Methods: \n",
    "\n",
    "In order to solve our research question, there are a few key methods that are vital in helping us analyze the data we were given:\n",
    "\n",
    "*Exploratory Data Analysis (EDA)*\n",
    "\n",
    "+ **Correlation Matrices:** To identify potential relationships between variables and remove predictors with extreme correlation values.\n",
    "\n",
    "+ **Histograms and Boxplots:** These will be used to visualize the distribution of key variables and identify outliers or skewness in the data, providing insights into the data's characteristics.\n",
    "\n",
    "+ **Principal Component Analysis (PCA):** PCA will be applied to reduce the dimensionality of the dataset, identifying a smaller number of uncorrelated variables (principal components) that capture most of the variance in the data.\n",
    "\n",
    "*Predictive Modeling*\n",
    "\n",
    "+ **Logistic Regression:** A baseline model due to its interpretability and effectiveness in binary classification tasks.\n",
    "Decision Trees and Random Forests: These models are useful for handling nonlinear relationships and interactions between variables.\n",
    "\n",
    "+ **K-Nearest Neighbors (KNN):** To explore the predictive power of player similarities in the context of All-Star selections.\n",
    "\n",
    "+ **Linear Discriminant Analysis (LDA):** As a technique to find a linear combination of features that characterizes or separates two or more classes (All-Star selected/not selected).\n",
    "\n",
    "+ **Neural Networks:** To model complex nonlinear relationships through a deep learning approach, potentially capturing intricate patterns in the data.\n",
    "\n",
    "+ **XGBoost:** A gradient boosting framework that has been successful in various prediction tasks, known for its performance and speed.\n",
    "\n",
    "*Addressing Potential Issues*\n",
    "\n",
    "+ **Multicollinearity:** Before deploying logistic regression and other linear models, the correlation will be calculated and the raw data sources analyzed to identify and mitigate multicollinearity among predictors.\n",
    "\n",
    "+ **Overfitting:** Regularization techniques, along with validation methods such as holdout-validation, will be applied to prevent overfitting, especially in complex models like neural networks and random forests.\n",
    "\n",
    "By employing these methods, the determinants of NBA All-Star can be selected accurately, providing both predictive power and insights into the importance and influence of various factors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation and Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = select(nbadf, Not([:Player, :Pos, :Tm, :ALLSTAR,:GS]))\n",
    "vars = names(numeric_df)\n",
    "X = Matrix(numeric_df)\n",
    "M = cor(X)\n",
    "fig = heatmap(M, \n",
    "    title=\"Correlation Matrix - All Predictors\", \n",
    "    xticks=(1:26, vars), \n",
    "    yticks=(1:26, vars), \n",
    "    clims=(-1,1), \n",
    "    xrot=45,\n",
    "    color=cgrad(:balance, rev=true), \n",
    "    aspect=:ratio, \n",
    "    size=(900, 800)\n",
    ")\n",
    "\n",
    "for j in axes(M,2), i in axes(M,1)\n",
    "    annotate!(i,j, text(\"$(round(M[i,j], digits=2))\", :white, 8))\n",
    "end \n",
    "fig "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Check for multicollinearity\n",
    "\n",
    "The following predictors were removed from the dataset due to high correlation and issues with multicollinearity:\n",
    "+ Shot attempts: high correlation between shots made and attempts, better to use shots made and shot pct\n",
    "+ eFGpct: According to [basketball-reference.com](https://www.basketball-reference.com/about/glossary.html), eFGpct = (FG + 0.5 * 3P) / FGA which is a linear equation of predictors\n",
    "+ Field Goals: Field goals is just 2P + 3P, so it is collinear\n",
    "+ Total Rebounds: Total rebounds is offensive + defensive rebounds, which is collinear\n",
    "+ Recommendation: Remove these predictors when creating linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = names(select(numeric_df, Not([:FG,:FGA,:FGpct,:ThreePA,:TwoPA,:FTA,:TRB,:eFGpct, :PPG])))\n",
    "X = Matrix(select(numeric_df, Not([:FG,:FGA,:FGpct,:ThreePA,:TwoPA,:FTA,:TRB,:eFGpct, :PPG])))\n",
    "M = cor(X)\n",
    "fig = heatmap(M, \n",
    "    title=\"Correlation Matrix\", \n",
    "    xticks=(1:17, vars), \n",
    "    yticks=(1:17, vars), \n",
    "    clims=(-1,1), \n",
    "    xrot=45,\n",
    "    color=cgrad(:balance, rev=true), \n",
    "    aspect=:ratio, \n",
    "    size=(900, 800)\n",
    ")\n",
    "\n",
    "for j in axes(M,2), i in axes(M,1)\n",
    "    annotate!(i,j, text(\"$(round(M[i,j], digits=2))\", :white, 8))\n",
    "end \n",
    "fig "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there are still a few predictors with high correlation, the overall correlation looks much better and the concerns of multicollinearity have been removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make a ColorGradient for Heatmaps: color_palette = cgrad(Sample color scheme = :roma, scale = :log))\n",
    "@df nbadf scatter(:MP, :PPG, group = :ALLSTAR, \n",
    "smooth = true, linewidth = 4,\n",
    "title = \"Playtime efficiency\",\n",
    "xlabel = \"Minutes played per game\",\n",
    "ylabel = \"Points per game\",\n",
    "label = [\"Players\" \"Allstars\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatterplot of minutes played against points per game appears to be non-linear until the Allstar status is labeled on the points. Then we see that there is not as much of a non-linear relationship but actually two different linear relationships, where Allstars play more minutes and have a higher rate of scoring points during their playing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter(row->row.ALLSTAR==(\"Y\") && row.MP<25,nbadf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While most Allstars had high playing time, there appeared to be a few outliers who played less than 25 minutes per game. These players in general were dealing with injuries or older age which limited their play time during this season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedhist(nbadf.Age, group=nbadf.ALLSTAR, bar_position = :stack,\n",
    "title = \"Player Age Distribution\",\n",
    "xlabel = \"Age\",\n",
    "ylabel = \"Count\",\n",
    "label = [\"Players\" \"Allstars\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@df nbadf scatter(:ThreePA, :TwoPA, group = :ALLSTAR,\n",
    "title = \"Shot Attempts Per Game\",\n",
    "xlabel = \"Three Point Attempts\",\n",
    "ylabel = \"Two Point Attempts\",\n",
    "label = [\"Players\" \"Allstars\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot(nbadf.Age, nbadf.G, xlabel=\"Age\", ylabel=\"Games Played\", label= nothing, \n",
    "size=(600, 300))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = names(numeric_df)\n",
    "# load the PCA model\n",
    "PCA = @load PCA pkg = MultivariateStats\n",
    "\n",
    "# Standarize -> PCA w/ 97.5% variance.\n",
    "# The mean = 0 option means we do not need to center the data.\n",
    "model = Pipeline(Standardizer(), PCA(variance_ratio = 0.975))\n",
    "\n",
    "# Fit the machine.\n",
    "mach = machine(model, numeric_df) |> MLJ.fit!\n",
    "\n",
    "# Apply a transformation to the numeric data and convert to Matrix.\n",
    "Xproj = MLJ.transform(mach, numeric_df) |> Matrix\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = report(mach).pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = nbadf[:, :ALLSTAR] |> Vector\n",
    "scatter(Xproj[:, 1], Xproj[:, 2],\n",
    "  group = y,\n",
    "  title = \"NBA Data in PC coordinates\",\n",
    "  xlabel = \"PC1\",\n",
    "  ylabel = \"PC2\",\n",
    "  label = [\"Players\" \"Allstars\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = nbadf[:, :ALLSTAR] |> Vector\n",
    "scatter(Xproj[:, 1], Xproj[:, 2], Xproj[:, 3],\n",
    "  group = y,\n",
    "  title = \"NBA Data in PC coordinates\",\n",
    "  xlabel = \"PC1\",\n",
    "  ylabel = \"PC2\",\n",
    "  zlabel = \"PC3\",\n",
    "  label = [\"Players\" \"Allstars\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = r.loadings\n",
    "loadings_df = hcat(\n",
    "  DataFrame(feature = features),\n",
    "  DataFrame(L, :auto)\n",
    ")\n",
    "\n",
    "rename!(loadings_df, [:feature, :PC1, :PC2, :PC3])\n",
    "loadings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive scatterplot from PlotlyJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA_df = DataFrame(:ALLSTAR=>nbadf[:,:ALLSTAR],:X1=>Xproj[:, 1],:X2=>Xproj[:, 2],:X3=>Xproj[:,3])\n",
    "\n",
    "# colors = [RGB(18/255, 133/255, 248/255), RGB(217/255, 89/255, 56/255)]\n",
    "# data = PJS.GenericTrace[]\n",
    "# df = filter(:ALLSTAR=>==(\"N\"),PCA_df)\n",
    "# PC1=df[:,:X1]\n",
    "# PC2=df[:,:X2]\n",
    "# PC3=df[:,:X3]\n",
    "# trace = PJS.scatter3d(name=\"Players\", mode=\"markers\",\n",
    "#                     marker_size=3, marker_color=colors[1], marker_line_width=0,\n",
    "#                     x=PC1, y=PC2, z=PC3)\n",
    "# push!(data, trace)\n",
    "# cluster = PJS.mesh3d(color=colors[1], opacity=0.3, x=PC1, y=PC2, z=PC3)\n",
    "# push!(data, cluster)\n",
    "\n",
    "# df = filter(:ALLSTAR=>==(\"Y\"),PCA_df)\n",
    "# PC1=df[:,:X1]\n",
    "# PC2=df[:,:X2]\n",
    "# PC3=df[:,:X3]\n",
    "# trace = PJS.scatter3d(name=\"Allstars\", mode=\"markers\",\n",
    "#                     marker_size=3, marker_color=colors[2], marker_line_width=0,\n",
    "#                     x=PC1, y=PC2, z=PC3)\n",
    "# push!(data, trace)\n",
    "# cluster = PJS.mesh3d(color=colors[2], opacity=0.3, x=PC1, y=PC2, z=PC3)\n",
    "# push!(data, cluster)\n",
    "# # notice the nested attrs to create complex JSON objects\n",
    "# layout = PJS.Layout(width=800, height=550, autosize=false, title=\"Interactive NBA Data in PC coordinates\",\n",
    "#                 scene=PJS.attr(xaxis=PJS.attr(gridcolor=\"rgb(255, 255, 255)\",\n",
    "#                                         zerolinecolor=\"rgb(255, 255, 255)\",\n",
    "#                                         showbackground=true,\n",
    "#                                         backgroundcolor=\"rgb(230, 230,230)\",\n",
    "#                                         title = \"PC1\"),\n",
    "#                             yaxis=PJS.attr(gridcolor=\"rgb(255, 255, 255)\",\n",
    "#                                         zerolinecolor=\"rgb(255, 255, 255)\",\n",
    "#                                         showbackground=true,\n",
    "#                                         backgroundcolor=\"rgb(230, 230,230)\",\n",
    "#                                         title = \"PC2\"),\n",
    "#                             zaxis=PJS.attr(gridcolor=\"rgb(255, 255, 255)\",\n",
    "#                                         zerolinecolor=\"rgb(255, 255, 255)\",\n",
    "#                                         showbackground=true,\n",
    "#                                         backgroundcolor=\"rgb(230, 230,230)\",\n",
    "#                                         title = \"PC3\"),\n",
    "#                             aspectratio=PJS.attr(x=1, y=1, z=0.7),\n",
    "#                             aspectmode = \"manual\"),\n",
    "#                             scene_camera = PJS.attr(eye=PJS.attr(x=1.25, y=-2, z=.75) # Try to match Plots output\n",
    "#                             ))\n",
    "# # p = PJS.plot(data, layout)\n",
    "# # open(\"./PCA3D.html\", \"w\") do io\n",
    "# #     PJS.PlotlyBase.to_html(io, p.plot)\n",
    "# # end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe width=900 height=600 src=\"./PCA3D.html\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = categorical(String.(nbadf[!, :ALLSTAR]), levels = [\"N\", \"Y\"])\n",
    "X = select(numeric_df, Not([:FG,:FGA,:FGpct,:ThreePA,:TwoPA,:FTA,:TRB,:eFGpct, :PPG]))\n",
    "X.Age2 = X.Age.^2 \n",
    "X.Pos = categorical(nbadf.Pos) \n",
    "\n",
    "#Code from Lecture 19\n",
    "train, test = partition(eachindex(y), 0.8, shuffle=true, rng=206);\n",
    "acc = Float64[] # accuracy()\n",
    "pre = Float64[] # multiclass_precision()\n",
    "rec = Float64[] # multiclass_recall()\n",
    "f1s = Float64[] # f1score()\n",
    "mat = []        # confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code from Lecture 19\n",
    "KNNClassifier = @load KNNClassifier verbosity = 0\n",
    "LDA = @load LDA verbosity = 0\n",
    "NeuralNetworkClassifier = @load NeuralNetworkClassifier pkg = MLJFlux verbosity = 0\n",
    "#MultinomialClassifier = @load MultinomialClassifier verbosity = 0 #not needed, same as logistic when only 2 classes\n",
    "DecisionTreeClassifier = @load DecisionTreeClassifier pkg = DecisionTree verbosity=0\n",
    "RandomForestClassifier = @load RandomForestClassifier pkg=DecisionTree verbosity=0\n",
    "LogisticClassifier = @load LogisticClassifier pkg= MLJLinearModels verbosity=0\n",
    "XGBoostClassifier = @load XGBoostClassifier pkg = XGBoost verbosity=0\n",
    "model_list = [\n",
    "    KNNClassifier(K = 5), # use nearest 5-neighbors to make predictions\n",
    "    LDA(),\n",
    "    NeuralNetworkClassifier(epochs = 20),\n",
    "    #MultinomialClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticClassifier(),\n",
    "    XGBoostClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code from Lecture 19\n",
    "for clf in model_list\n",
    "    Random.seed!(206)\n",
    "    # Create a pipeline model that standardizes, then fits a classifier.\n",
    "    model = Pipeline(Standardizer(), \n",
    "                        OneHotEncoder(),\n",
    "                        clf)\n",
    "    # Fit the model onto the training set\n",
    "    mach = machine(model, X, y)\n",
    "    fit!(mach, rows = train, verbosity = 0)\n",
    "    # Make predictions on the test set\n",
    "    yhat = MLJ.predict(mach, rows = test)\n",
    "    # Evaluate the model on the test set using selected metrics\n",
    "    #\n",
    "    # NOTES:\n",
    "    #\n",
    "    #   - MLJ.predict() may give probabilistic predictions. Use mode() to collapse to a concrete target.\n",
    "    #   - An evaluation metric F() always accepts inputs as F(fitted, observed).\n",
    "    #\n",
    "    push!(acc, accuracy(mode.(yhat), y[test]))\n",
    "    push!(pre, multiclass_precision(mode.(yhat), y[test]))\n",
    "    push!(rec, multiclass_recall(mode.(yhat), y[test]))\n",
    "    push!(f1s, f1score(mode.(yhat), y[test]))\n",
    "    push!(mat, ConfusionMatrix(levels = levels(y))(mode.(yhat), y[test]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code from Lecture 19\n",
    "results = DataFrame(\n",
    "    Model = typeof.(model_list),\n",
    "    Accuracy = acc,\n",
    "    Precision = pre,\n",
    "    Recall = rec,\n",
    "    F1 = f1s\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat[1]  # KNNClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat[2]  # LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat[3]  # NeuralNetworkClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat[4] #Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat[5] #Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat[6] #Logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat[7] #XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(Standardizer(), OneHotEncoder(), LogisticClassifier())\n",
    "    # Fit the model onto the training set\n",
    "    mach = machine(model, X, y_encode)\n",
    "    fit!(mach, verbosity = 0)\n",
    "fitted_params(mach).logistic_classifier.coefs |> DataFrame\n",
    "#MLJ.predict(mach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
